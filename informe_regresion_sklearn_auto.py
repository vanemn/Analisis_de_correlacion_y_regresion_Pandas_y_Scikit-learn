#  Librer√≠as de an√°lisis, gr√°ficos y modelo predictivo
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages  # Para exportar m√∫ltiples gr√°ficas al mismo PDF
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.model_selection import cross_val_score

#  Cargar dataset
df = pd.read_csv("science_data1.csv")  # Carga el archivo CSV con los datos
objetivo = 'crecimiento_planta'        # Define la variable objetivo que queremos predecir

#  Selecci√≥n autom√°tica de variables predictoras num√©ricas
X_full = df.select_dtypes(include='number').drop(columns=[objetivo])  # Selecciona todas las columnas num√©ricas excepto la variable objetivo
y = df[objetivo]  # Define el vector de salida (objetivo)

#  Seleccionamos autom√°ticamente las 5 mejores variables seg√∫n test estad√≠stico F
k = min(5, X_full.shape[1])  # k ser√° 5 o el n√∫mero m√°ximo disponible de columnas
selector = SelectKBest(score_func=f_regression, k=k)
selector.fit(X_full, y)  # Aplica el selector al conjunto de datos

#  Lista de columnas seleccionadas como predictoras relevantes
predictoras = X_full.columns[selector.get_support()].tolist()

#  Mostrar las variables seleccionadas
print(" Variables seleccionadas autom√°ticamente:")
for v in predictoras:
    print(f"‚Ä¢ {v}")

#  Definir subconjunto de datos con las columnas seleccionadas
X = df[predictoras]

#  Crear informe PDF con todo el an√°lisis
with PdfPages("informe_regresion_sklearn.pdf") as pdf:

    #  P√°gina 1: Matriz de correlaciones entre variables seleccionadas
    plt.figure(figsize=(10, 8))
    matriz = df[predictoras + [objetivo]].corr()
    sns.heatmap(matriz, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title(" Matriz de Correlaci√≥n")
    plt.tight_layout()
    pdf.savefig()
    plt.close()

    #  P√°gina 2+: Regresiones simples por variable
    for var in predictoras:
        X_simple = df[[var]]
        y_simple = df[objetivo]

        # Entrena modelo lineal simple
        modelo = LinearRegression().fit(X_simple, y_simple)
        y_pred = modelo.predict(X_simple)

        # M√©tricas de desempe√±o
        r2 = r2_score(y_simple, y_pred)
        mse = mean_squared_error(y_simple, y_pred)
        mae = mean_absolute_error(y_simple, y_pred)

        # Crear gr√°fico
        fig, ax = plt.subplots(figsize=(11.69, 8.27))
        ax.scatter(X_simple, y_simple, color='skyblue', label='Datos reales')
        ax.plot(X_simple, y_pred, color='red', label='Regresi√≥n')
        ax.set_xlabel(var)
        ax.set_ylabel(objetivo)
        ax.set_title(f" Regresi√≥n: {var} ‚Üí {objetivo} | R¬≤ = {r2:.2f}")
        ax.legend()

        # Interpretaci√≥n textual en la parte inferior
        texto = (
            f" Resultados de la regresi√≥n simple con '{var}':\n"
            f"‚Ä¢ Intercepto: {modelo.intercept_:.2f}\n"
            f"‚Ä¢ Coeficiente: {modelo.coef_[0]:.4f}\n"
            f"‚Ä¢ R¬≤: {r2:.3f} | MAE: {mae:.2f} | MSE: {mse:.2f}\n"
            f"‚Ä¢ Relaci√≥n: {'fuerte' if r2 > 0.6 else 'moderada' if r2 > 0.3 else 'd√©bil'}"
        )
        plt.figtext(0.05, 0.02, texto, ha='left', va='bottom', fontsize=10)
        plt.tight_layout(rect=[0, 0.07, 1, 1])
        pdf.savefig()
        plt.close()

    # üßÆ √öltima p√°gina: Regresi√≥n lineal m√∫ltiple
    modelo_multi = LinearRegression().fit(X, y)  # Entrena modelo con varias variables
    y_pred_multi = modelo_multi.predict(X)

    # M√©tricas de desempe√±o
    r2_multi = r2_score(y, y_pred_multi)
    mse_multi = mean_squared_error(y, y_pred_multi)
    mae_multi = mean_absolute_error(y, y_pred_multi)

    # Evaluaci√≥n con validaci√≥n cruzada
    cv_scores = cross_val_score(modelo_multi, X, y, cv=5, scoring='r2')

    # P√°gina resumen con texto
    fig, ax = plt.subplots(figsize=(11.69, 8.27))
    ax.axis("off")  # Oculta ejes para dejar espacio a texto

    texto_final = f"""
 Resumen de Regresi√≥n M√∫ltiple

‚Ä¢ Variables predictoras: {', '.join(predictoras)}
‚Ä¢ Intercepto: {modelo_multi.intercept_:.2f}
‚Ä¢ R¬≤ entrenamiento: {r2_multi:.3f} | MAE: {mae_multi:.2f} | MSE: {mse_multi:.2f}
‚Ä¢ R¬≤ validaci√≥n cruzada (5 folds): {cv_scores.mean():.3f} (range {cv_scores.min():.3f}‚Äì{cv_scores.max():.3f})

Coeficientes del modelo:"""

    # Mostrar coeficientes por variable
    for var, coef in zip(predictoras, modelo_multi.coef_):
        texto_final += f"\n  ‚Ä¢ {var}: {coef:.4f}"

    texto_final += (
        "\n\n Conclusi√≥n:\nEste modelo explica aproximadamente "
        f"el {r2_multi*100:.1f}% de la variabilidad del objetivo. "
        "Puede servir para predicci√≥n, aunque tambi√©n se recomienda validar con nuevos datos y explorar modelos alternativos."
    )

    # Dibujar texto l√≠nea por l√≠nea en el PDF
    for i, linea in enumerate(texto_final.strip().split('\n')):
        fig.text(0.05, 0.95 - i * 0.035, linea.strip(), fontsize=10, ha='left')

    # Guardar p√°gina final
    pdf.savefig()
    plt.close()

#  Fin
print(" Informe completo generado: 'informe_regresion_sklearn.pdf'")